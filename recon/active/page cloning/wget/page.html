<!DOCTYPE html  PUBLIC '-//W3C//DTD XHTML 1.0 Transitional//EN'  'http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd'><html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<title>Wget</title>
</head><body><b><span style="font-size: 14pt">Wget</span><br/>
</b><tt>https://linux.die.net/man/1/wget</tt><b><br/>
</b><b><br/>
non-interactive network downloader<br/>
<br/>
<br/>
</b><b><span style="font-size: 12pt">Switches</span></b><br/>
<br/>
-r				download recursively (follow every link)<tt><br/>
</tt>-l				crawl depth<br/>
-k				convert links to point to local files<br/>
-p				get all images even from external pages<br/>
--random-wait 	wait from 0.5*WAIT...1.5*WAIT secs between retrievals<tt><br/>
</tt><tt><br/>
<br/>
</tt><b><span style="font-size: 12pt">Example</span></b><tt><br/>
</tt><tt><br/>
</tt><b>Site cloning</b><tt><br/>
</tt><tt><br/>
wget -r -k -l 5 http://172.16.253.140/bodgeit/<br/>
</tt></body></html>